---
title: Deep Learning: A Critical Appraisal
authors: Gary Marcus
year: 
---

# Deep Learning: A Critical Appraisal
Gary Marcus()
[Zotero-Link](zotero://select/items/@marcusDeepLearningCritical)

>[!ABSTRACT]-
>Although deep learning has historical roots going back decades, neither the term “deep learning” nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton’s now classic 2012 (Krizhevsky, Sutskever, & Hinton, 2012)deep net model of Imagenet.

---

# Annotations  
(11/29/2022, 7:54:16 AM)

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=1&annotation=GHYI5N8Q)“nd suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence” ([Marcus, p. 1](zotero://select/library/items/DVP6YCNJ)) with the goal in mind to reach artificial general intelligence

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=2&annotation=E2NJH26J)“and it rapidly became the best known technique in artificial 2 intelligence, by a wide margin” ([Marcus, p. 2](zotero://select/library/items/DVP6YCNJ))

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=2&annotation=8D4WI5II)“because of increases in computational power and data, the first time that deep learning truly became practical” ([Marcus, p. 2](zotero://select/library/items/DVP6YCNJ)) the deep learning revolution was possible because of data and computational power

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=3&annotation=W23U92FI)“nd what has its shown about the nature of intelligence?” ([Marcus, p. 3](zotero://select/library/items/DVP6YCNJ)) important question connecting DL and CCN

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=4&annotation=GUT6ZEFS)“n algorithm called back-propagation allows a process called gradient descent to adjust the connections between units using a process, such that any given input tends to produce the corresponding output” ([Marcus, p. 4](zotero://select/library/items/DVP6YCNJ)) does he generalize since back-propagation is not the only learning rule

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=5&annotation=EVWLUDSQ)“iven infinite data, deep learning systems are powerful enough to represent any finite deterministic “mapping” between any given set of inputs and a set of corresponding outputs” ([Marcus, p. 5](zotero://select/library/items/DVP6YCNJ)) is more data better for a system?

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=5&annotation=22KJVUF8)“local minima” ([Marcus, p. 5](zotero://select/library/items/DVP6YCNJ))

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=6&annotation=NYBGS2SA)“As discussed later in this article, generalization can be thought of as coming in two flavors, interpolation between known examples, and extrapolation, which requires going beyond a space of known training examples” ([Marcus, p. 6](zotero://select/library/items/DVP6YCNJ))

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=7&annotation=UPXNTRVS)“lacks a mechanism for learning abstractions through explicit” ([Marcus, p. 7](zotero://select/library/items/DVP6YCNJ))

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=7&annotation=6YIA9UXN)“works best when there are thousands, millions or even billions of training examples” ([Marcus, p. 7](zotero://select/library/items/DVP6YCNJ))

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=7&annotation=M9RNUM6L)“and my own work with Steven Pinker on children’s overregularization errors in comparison to neural networks” ([Marcus, p. 7](zotero://select/library/items/DVP6YCNJ)) interesting study, should look at it

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=7&annotation=AX6Z4W7B)“transformation we have to chose between replicating feature detectors on a grid that grows exponentially ... or increasing the size of the labelled training set in a similarly exponential way” ([Marcus, p. 7](zotero://select/library/items/DVP6YCNJ)) i do not fully understand, but he says that convolutional networks have a bias built into its architecture

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=7&annotation=VZJLGQQ8)“n problems where data are limited, deep learning often is not an ideal solution” ([Marcus, p. 7](zotero://select/library/items/DVP6YCNJ)) deep learning is made possible by the large amount of data

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=8&annotation=VIA7FMXI)“such remarks are what comparative (animal) psychology sometimes call overattributions” ([Marcus, p. 8](zotero://select/library/items/DVP6YCNJ)) comparison between reinforcement learning and animal psychology: overattribution

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=9&annotation=S7QRHKEP)“anguage has a hierarchical structure, in which larger structures are recursively constructed out of smaller components” ([Marcus, p. 9](zotero://select/library/items/DVP6YCNJ))

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=14&annotation=8KRJG8YY)“machine learning lacks the capacity to produce comparable guarantees” ([Marcus, p. 14](zotero://select/library/items/DVP6YCNJ))

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=14&annotation=2KHGVNQ2)“machine learning as yet lacks the incrementality, transparency and debuggability of classical programming” ([Marcus, p. 14](zotero://select/library/items/DVP6YCNJ))

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=15&annotation=CEDV4BZM)“deep learning is a perfectly fine way of optimizing a complex system for representing a mapping between inputs and outputs, given a sufficiently large data set” ([Marcus, p. 15](zotero://select/library/items/DVP6YCNJ))

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=15&annotation=3RD8WK3Y)“eep learning is just a statistical technique,” ([Marcus, p. 15](zotero://select/library/items/DVP6YCNJ))

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=15&annotation=SVALBF3H)“work less well when there are limited amounts of training data available” ([Marcus, p. 15](zotero://select/library/items/DVP6YCNJ)) deep learning needs the data

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=17&annotation=GBICPJXB)“As yet there is no general solution within deep learning to the problem of generalizing outside the training space.” ([Marcus, p. 17](zotero://select/library/items/DVP6YCNJ)) this is not similar to humans at all, DL can't extrapolate

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=18&annotation=5RG2WENF)“but simply as one tool among many” ([Marcus, p. 18](zotero://select/library/items/DVP6YCNJ))

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=18&annotation=XV3PHQ66)“In perceptual classification, where vast amounts of data are available, deep learning is a valuable tool; in other, richer cognitive domains, it is often far less satisfactory.” ([Marcus, p. 18](zotero://select/library/items/DVP6YCNJ))

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=19&annotation=L4E6LH5F)“unsupervised learning” ([Marcus, p. 19](zotero://select/library/items/DVP6YCNJ))

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=19&annotation=6GUHGCWJ)“One is still left with data hungry systems that lack explicit variables, and I see no advance there towards open-ended inference, interpretability or debuggability.” ([Marcus, p. 19](zotero://select/library/items/DVP6YCNJ)) unsupervised learning still needs a lot of data and doesnt solve the stated problems

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=19&annotation=EPBGSNWR)“If we could build systems that could set their own goals and do reasoning and problem-solving at this more abstract level, major progress might quickly follow.” ([Marcus, p. 19](zotero://select/library/items/DVP6YCNJ)) an abstract proposal of the next kind of algorithms to learn like children do

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=20&annotation=K7FUTBUG)“The right move today may be to integrate deep learning, which excels at perceptual classification, with symbolic systems, which excel at inference and abstraction.” ([Marcus, p. 20](zotero://select/library/items/DVP6YCNJ))

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=20&annotation=R72KS64G)“he power and flexibility of the brain comes in part from its capacity to dynamically integrate many different computations in real-time.” ([Marcus, p. 20](zotero://select/library/items/DVP6YCNJ))

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=20&annotation=2DYQYFZC)“neurosymbolic modeling (Besold et al., 2017)” ([Marcus, p. 20](zotero://select/library/items/DVP6YCNJ)) a new approach to connect deep learning and abstractions from classical AI

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=20&annotation=QPUCC8DC)“I have long argued (Marcus, 2001) that more on integrating microprocessorlike operations into neural networks could be extremely valuable.” ([Marcus, p. 20](zotero://select/library/items/DVP6YCNJ)) this could be interesting to read

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=21&annotation=T8TPVR89)“We don’t yet know enough about neuroscience to literally reverse engineer the brain, per se, and may not for several decades, possibly until AI itself gets better. AI can help us to decipher the brain, rather than the other way around.” ([Marcus, p. 21](zotero://select/library/items/DVP6YCNJ)) a nice understanding of why we use deep learning to model the brain -> because we don't have enough knowledge yet to reverse-engineer the brain

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=21&annotation=NXPPVCWI)“I summarize a number of possibilities, some drawn from my own earlier work (Marcus, 2001) and others from Elizabeth Spelke’s (Spelke & Kinzler, 2007).” ([Marcus, p. 21](zotero://select/library/items/DVP6YCNJ)) something to read about cognitive inspirations for AI

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=22&annotation=KKBWSIBE)“A third focus might be on human understanding of narrative, a notion long ago suggested by Roger Schank and Abelson (1977) and due for a refresh (Marcus, 2014; Kočiský et al., 2017).” ([Marcus, p. 22](zotero://select/library/items/DVP6YCNJ)) might also be interesting to read about "narrative"

[Go to annotation](zotero://open-pdf/library/items/84FCSIS2?page=22&annotation=2V2IGIM9)“No specific supervised training set can cover all the possible contingencies; infererence and real-world knowledge integration are necessities.” ([Marcus, p. 22](zotero://select/library/items/DVP6YCNJ)) isn't this now possible with a language model which was presented in the NLP lecture?