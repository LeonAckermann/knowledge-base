202212030815
Status: #note
Tags: [[Computational Linguistics]], [[Vector Semantics and Embeddings]], [[skip-gram]]

# Word Embeddings

>[!Definition]
>An embedding represents  a word as a short dense vector, with dimension d (50-100). The dimensions cannot be clearly interpreted in any real sense. A dense vector has most of its entries filled either with positive or negative values.

>[!Motivation]





# References
[[@jurafskySpeechLanguageProcessing]]